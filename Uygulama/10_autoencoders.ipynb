{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://youtu.be/zp8clK9yCro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_DIR = \"mnist/\"\n",
    "\n",
    "X_mnist = idx2numpy.convert_from_file(MNIST_DIR + \"train-images-idx3-ubyte\")\n",
    "X_mnist = X_mnist.reshape(60000, -1) / 255.0\n",
    "y_mnist = idx2numpy.convert_from_file(MNIST_DIR + \"train-labels-idx1-ubyte\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_mnist, y_mnist, test_size=0.2, random_state=42)\n",
    "\n",
    "x = torch.from_numpy(X_train.astype(np.float32))\n",
    "y = torch.from_numpy(y_train.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.int64))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MnistDataset(X_train, y_train)\n",
    "data_loader_train = DataLoader(\n",
    "    dataset=dataset_train, \n",
    "    batch_size=64, \n",
    "    shuffle=True)\n",
    "\n",
    "dataset_test = MnistDataset(X_test, y_test)\n",
    "data_loader_test = DataLoader(\n",
    "    dataset=dataset_test, \n",
    "    batch_size=64, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(image), torch.max(image))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for images, _ in data_loader_train:\n",
    "        reconstructed_images = model(images)\n",
    "        loss = criterion(reconstructed_images, images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, title):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.box(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title)\n",
    "    for i in range(9):\n",
    "        img = images[i].numpy().reshape((28, 28))\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(data_loader_test))\n",
    "plot_images(images, \"Source Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = None\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = model(images)\n",
    "print(reconstructed_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(reconstructed_images, \"Reconstructed Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_images = None\n",
    "with torch.no_grad():\n",
    "    encoded_images = model.encoder(images)\n",
    "\n",
    "print(encoded_images.shape)\n",
    "\n",
    "decoded_images = None\n",
    "with torch.no_grad():\n",
    "    decoded_images = model.decoder(encoded_images)\n",
    "\n",
    "print(decoded_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(decoded_images, \"Decoded Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist = idx2numpy.convert_from_file(MNIST_DIR + \"train-images-idx3-ubyte\")\n",
    "X_mnist = X_mnist.reshape((-1, 1, 28, 28)) / 255.0\n",
    "y_mnist = idx2numpy.convert_from_file(MNIST_DIR + \"train-labels-idx1-ubyte\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_mnist, y_mnist, test_size=0.2, random_state=42)\n",
    "\n",
    "x = torch.from_numpy(X_train.astype(np.float32))\n",
    "y = torch.from_numpy(y_train.astype(np.int64))\n",
    "\n",
    "dataset_train = MnistDataset(X_train, y_train)\n",
    "data_loader_train = DataLoader(\n",
    "    dataset=dataset_train, \n",
    "    batch_size=64, \n",
    "    shuffle=True)\n",
    "\n",
    "dataset_test = MnistDataset(X_test, y_test)\n",
    "data_loader_test = DataLoader(\n",
    "    dataset=dataset_test, \n",
    "    batch_size=64, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(dataset_train))\n",
    "print(image.shape, torch.min(image), torch.max(image))\n",
    "image = image.numpy()\n",
    "print(image.shape)\n",
    "image = image.squeeze()\n",
    "print(image.shape)\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in data_loader_train:\n",
    "    print(\"Original shape:\", images.shape)\n",
    "    x = nn.Conv2d(1, 16, 3, stride=2, padding=1)(images)\n",
    "    print(\"After Conv2d(64, 16, 3, stride=2, padding=1):\", x.shape)\n",
    "    x = nn.Conv2d(16, 32, 3, stride=2, padding=1)(x)\n",
    "    print(\"After Conv2d(16, 32, 3, stride=2, padding=1):\", x.shape)\n",
    "    x = nn.Conv2d(32, 64, 7)(x)\n",
    "    print(\"After Conv2d(32, 64, 7):\", x.shape)\n",
    "    x = nn.ConvTranspose2d(64, 32, 7)(x)\n",
    "    print(\"After ConvTranspose2d(64, 32, 7):\", x.shape)\n",
    "    x = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)(x)\n",
    "    print(\"After ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1):\", x.shape)\n",
    "    x = nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1)(x)\n",
    "    print(\"After ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1):\", x.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 dk\n",
    "model_cnn = AutoEncoderCNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images, _ in data_loader_train:\n",
    "        reconstructed_images = model_cnn(images)\n",
    "        loss = criterion(reconstructed_images, images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(data_loader_test))\n",
    "plot_images(images, \"Source Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = None\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = model_cnn(images)\n",
    "print(reconstructed_images.shape)\n",
    "\n",
    "plot_images(reconstructed_images, \"Reconstructed Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
